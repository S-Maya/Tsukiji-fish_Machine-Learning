{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR,LinearSVR\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the columns from the csv we will be reading\n",
    "COLS = ['Species', 'Weight', 'Length1', 'Length2', 'Length3', 'Height', 'Width']\n",
    "#this is the column with the value we are trying to predict\n",
    "Y_COL = ['Weight']\n",
    "X_COLS = []\n",
    "unique_fish = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = r\"fish_participant.csv\"\n",
    "# validation_data_path=r\"fish_holdout_demo.csv\"\n",
    "csv_path = os.path.join(\"fish_participant.csv\")\n",
    "validation_data_path = os.path.join(\"fish_holdout_demo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PickBestModelAndProcessor(csv_path, validation_data_path, models=[], processors=[]):\n",
    "    train_data = BuildDataFrame(csv_path)\n",
    "    test_data = BuildDataFrame(validation_data_path)\n",
    "    print(\"the top 5 rows look like this: \")\n",
    "    print(train_data.head())\n",
    "    y_train = train_data.drop(columns=[c for c in COLS if c not in Y_COL], inplace=False)\n",
    "    x_train_possible = train_data.drop(columns=Y_COL, inplace=False)\n",
    "    y_test = test_data.drop(columns=[c for c in COLS if c not in Y_COL], inplace=False)\n",
    "    x_test_possible = test_data.drop(columns=Y_COL, inplace=False)\n",
    "    MAX_FEATURES_COUNT=x_test_possible.shape[1]\n",
    "    results_list = []\n",
    "    best_score = 0\n",
    "    best_processor = None\n",
    "    best_model = None\n",
    "    best_feature_count=None\n",
    "    for n in range(1,MAX_FEATURES_COUNT+1):\n",
    "        for i in range(len(processors)):\n",
    "            print(\"preprocssing data with preprocessor number:\",str(i))\n",
    "            X_train,X_test = processors[i](x_train_possible, y_train, x_test_possible,n)\n",
    "            for j in range(len(models)):\n",
    "                print(\"training model number \"+str(j))\n",
    "                models[j].fit(X_train, y_train)\n",
    "                print(\"done training, we will see our accuracy rate now:\")\n",
    "                results=models[j].score(X_test,y_test)   ##this is ultimately what is needed in the homework is a model pass a X_test and y_test data to\n",
    "                print(\"the average deviation from the correct answer is: \"+str(results))\n",
    "                results_list.append(results)\n",
    "                if results>best_score and results <= 1.0 : #the best result possible is 1.0\n",
    "                    best_model=models[j]\n",
    "                    best_processor=processors[i]\n",
    "                    best_score = results\n",
    "                    best_features=X_test.columns.to_list()\n",
    "    return {\"best_score\":best_score,\"best_model\":best_model,\"best_processor\":best_processor,\"top_n_features\":best_features,\"all_results\":results_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no data processor\n",
    "def preprocess0(x,y,x2,n):\n",
    "    print(\"no preprocessing will happen in this function\")\n",
    "    return x,x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top n features\n",
    "def preprocess1(x,y,x2,n):\n",
    "    print(\"running processor 1 which will select top n features AND scale the feature values\")\n",
    "    anova_filter = SelectKBest(f_regression, k=n)\n",
    "    anova_filter.fit(x, y)\n",
    "    cols = anova_filter.get_support(indices=True)\n",
    "    print(\"out of a total of 6 features, the top 5 at predicting the weight are:\")\n",
    "    print(anova_filter.get_support())\n",
    "    X_train=x.iloc[:,cols]\n",
    "    X_test=x2.iloc[:,cols]\n",
    "    print(\"new training set: \")\n",
    "    print(X_train.head())\n",
    "    return  X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##select top n features AND scale the feature values\n",
    "def preprocess2(x,y,x2,n):\n",
    "    print(\"running processor 1 which will select top 5 features AND scale the feature values\")\n",
    "    anova_filter = SelectKBest(f_regression, k=n)\n",
    "    anova_filter.fit(x, y)\n",
    "    cols = anova_filter.get_support(indices=True)\n",
    "    print(\"out of a total of 6 features, the top 5 at predicting the weight are:\")\n",
    "    print(anova_filter.get_support())\n",
    "    X_train = x.iloc[:, cols]\n",
    "    X_test = x2.iloc[:, cols]\n",
    "    print(\"new training set: \")\n",
    "    print(X_train.head())\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train,y)\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns= X_train.columns)\n",
    "    X_test= pd.DataFrame(scaler.transform(X_test), columns= X_test.columns)\n",
    "    print(\"New X head values after scaling:\")\n",
    "    print(X_train.head())\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select top n features AND scale the feature values AND normalize the vector rows\n",
    "def preprocess3(x,y,x2,n):\n",
    "    print(\"running processor 1 which will select top 5 features AND scale the feature values AND normalize the vector rows\")\n",
    "    print(\"running processor 1 which will select top 5 features AND scale the feature values\")\n",
    "    anova_filter = SelectKBest(f_regression, k=n)\n",
    "    anova_filter.fit(x, y)\n",
    "    cols = anova_filter.get_support(indices=True)\n",
    "    print(\"out of a total of 6 features, the top 5 at predicting the weight are:\")\n",
    "    print(anova_filter.get_support())\n",
    "    X_train = x.iloc[:, cols]\n",
    "    X_test = x2.iloc[:, cols]\n",
    "    print(\"new training set: \")\n",
    "    print(X_train.head())\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train,y)\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns= X_train.columns)\n",
    "    X_test= pd.DataFrame(scaler.transform(X_test), columns= X_test.columns)\n",
    "    print(\"New X head values after scaling:\")\n",
    "    print(X_train.head())\n",
    "    normalize = Normalizer()\n",
    "    normalize.fit(X_train,y)\n",
    "    X_train=pd.DataFrame(normalize.fit_transform(X_train, y), columns = X_train.columns)\n",
    "    X_test=pd.DataFrame(normalize.fit_transform(X_test, y), columns = X_test.columns)\n",
    "    print(\"normalize vector columns\")\n",
    "    return X_train,X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MapFishName(n): \n",
    "    global unique_fish\n",
    "    if n not in unique_fish:\n",
    "        unique_fish.append(n)\n",
    "    return unique_fish.index(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildDataFrame(path):\n",
    "    with open(path, \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "        return pd.read_csv(f, header='infer', converters={'Species': MapFishName})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetermineBestModelAndProcessing():\n",
    "    processors=[preprocess0,preprocess1,preprocess2,preprocess3]\n",
    "    model1 = KNeighborsRegressor()\n",
    "    model2 = RandomForestRegressor()\n",
    "    model3 = RandomForestRegressor()\n",
    "    model4 = SVR()\n",
    "    model5 = LinearSVR()\n",
    "    models = [model1, model2, model3, model4, model5]\n",
    "    results=PickBestModelAndProcessor(csv_path, validation_data_path, models=models,processors=processors)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DetermineBestModelAndProcessing()\n",
    "#  Running a series of testes determines that of the models above\n",
    "#testing revealed the following best methods:\n",
    "#Best possible score is 1.00, we got 0.99506\n",
    "#{'best_score': 0.9950688891121598, 'best_model': RandomForestRegressor, 'best_processor':  preprocess0\n",
    "#we can also graph our values to see which features are most tightly bound to the y value, weight\n",
    "#for x in ['Species', 'Length1', 'Length2', 'Length3', 'Height', 'Width']:\n",
    "#     train_data.plot.scatter(x=x,y=['Weight'])\n",
    "#so lets build our final model and make a method to run questions against it\n",
    "def BuildAndTrainModel(csv_path,choice_model,DROP_FEATURES=[]):\n",
    "    SELECTED_X_FEATURES=['Length1', 'Length2', 'Length3', 'Height', 'Width']\n",
    "    Y_COL = ['Weight']\n",
    "    all_data=BuildDataFrame(csv_path)\n",
    "    y = all_data.drop(columns=[c for c in COLS if c not in Y_COL], inplace=False)\n",
    "    X = all_data.drop(columns=Y_COL+DROP_FEATURES, inplace=False)\n",
    "    choice_model.fit(X,y)\n",
    "    return choice_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-7653e9532fdb>:16: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  choice_model.fit(X,y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938525164572038\n"
     ]
    }
   ],
   "source": [
    "DROP_FEATURE=['Species']\n",
    "mymodel=RandomForestRegressor(n_estimators=115,criterion='mse')\n",
    "trained_model=BuildAndTrainModel(csv_path,mymodel,DROP_FEATURE)  \n",
    "validation_data=BuildDataFrame(validation_data_path)\n",
    "y_test=validation_data.drop(columns=[c for c in COLS if c not in Y_COL], inplace=False)\n",
    "X_test = validation_data.drop(columns=Y_COL+DROP_FEATURE, inplace=False)\n",
    "print(trained_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictASingleX(model,X):#we use this to predict a single weight based on a single input of x features.  X must in format of [[a,b,c,d]] or as a dataframe\n",
    "    print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error([y_true], [y_pred])\n",
    "def ScoreBasedOnMeanSquareError(model,X,y_true):  #returns score based on mean square error calculation\n",
    "    prediction=model.predict(X)\n",
    "    mse=mean_squared_error(y_true,prediction)\n",
    "    print(mse)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n",
      "574.0125655144478\n"
     ]
    }
   ],
   "source": [
    "reshape = lambda x: x.ravel().reshape(1,-1)\n",
    "scores1=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    result = ScoreBasedOnMeanSquareError(trained_model, X_test,y_test)\n",
    "    scores1.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bit9f9b16d984dc433badff5d8448edef5b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
